{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f60a3907de1f4d74",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "<div style=\"display:flex; align-items:center; gap:10px;\">\n",
    "  <img src=\"ece_logo.png\" width=\"198\" height=\"91\" alt=\"ECE logo\" />\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dca7af484fc9e553",
   "metadata": {},
   "source": [
    "# **Rapport de projet – Analyse de données et apprentissage automatique**\n",
    "## Réalisé par les étudiants de B3 Data & IA :\n",
    "## _Kenza BELALOUI - Anis FETOUAB - Nathan BRUNET - Oleksandr KSHYVNYAK - Sirine BESSOUS_\n",
    "\n",
    "### Ce projet a pour objectif de conduire un pipeline complet d’analyse de données, depuis le choix du dataset jusqu’à l’application d’un ou plusieurs modèles de machine learning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a57896a92314ed53",
   "metadata": {},
   "source": [
    "# Partie 1 – Définition du sujet et choix du dataset\n",
    "## 1.1 Thématique\n",
    "\n",
    "Notre projet se situe dans le domaine du sport, plus précisément l'analyse de données dans le football.\n",
    "\n",
    "L'objectif est de créer un modèle d'apprentissage automatique (machine learning) pour prédire si un joueur est un \"Top Attaquant\". Pour définir cette variable cible (TopAttacker), nous avons identifié les joueurs qui sont au-dessus de la médiane (la moyenne statistique) en GCA (Actions créant un but) et SCA (Actions créant un tir).\n",
    "\n",
    "Ce sujet mélange nos deux passions : le football et l'application concrète de la data science. Le défi était d'utiliser des statistiques avancées (au-delà des simples buts) pour modéliser une notion qui est d'habitude subjective.\n",
    "\n",
    "Ce projet sert concrètement au secteur sportif (clubs, médias) :\n",
    "\n",
    "1.\tAide au recrutement : Les clubs peuvent utiliser le modèle pour repérer des talents sous-évalués, en se basant sur des métriques avancées comme les GCA et SCA.\n",
    "2.\tAnalyse de performance : Les entraîneurs peuvent évaluer la contribution réelle d'un joueur à l'attaque, même s'il ne marque pas beaucoup.\n",
    "3.\tMédias et fans : Il fournit une base analytique pour comparer les joueurs et enrichir les débats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc585e5fe258942c",
   "metadata": {},
   "source": [
    "## 1.2 Recherche et sélection du dataset\n",
    "### Informations générales sur le dataset :\n",
    "\n",
    "Nom du dataset :\n",
    "Source et lien d’accès :\n",
    "Auteur ou organisation :\n",
    "Taille (nombre de lignes et de colonnes) : 2690 lignes et 97 colonnes\n",
    "Format du fichier (CSV, JSON, Excel, etc.) : Fichier en .CSV\n",
    "\n",
    "### Vérification de la qualité :\n",
    "Le dataset est-il récent ?\n",
    "Les variables sont-elles clairement nommées et documentées ?\n",
    "Contient-il suffisamment de données (au moins plusieurs centaines de lignes) ?\n",
    "Le dataset comporte-t-il une variable cible que vous pourrez prédire ou expliquer ?\n",
    "Les données semblent-elles complètes et cohérentes ?\n",
    "\n",
    "### Justification du choix :\n",
    "Le fichier était idéal car il contenait les stats de GCA (Actions créant un But) et SCA (Actions créant un Tir). C'est crucial, car ces deux métriques nous ont permis de construire la variable cible (TopAttacker). Le reste des données (passes progressives, tirs, etc.) a servi de features (variables explicatives) pour entraîner le modèle.\n",
    "\n",
    "#### Avantages\n",
    "\n",
    "Richesse : Le dataset est hyper complet, avec des dizaines de métriques avancées comme PasProg (Passes Progressives) et CarProg (Portées Progressives), ce qui donne une description très fine du profil de chaque joueur.\n",
    "\n",
    "- Comparabilité : Toutes les données sont ramenées \"par 90 minutes\" (90s), ce qui garantit une comparaison équitable entre les joueurs, peu importe leur temps de jeu total.\n",
    "\n",
    "- Qualité : Les performances sont issues d'une compétition de haut niveau (Ligue des Champions), ce sont donc des données très pertinentes.\n",
    "\n",
    "#### Limites et Difficultés\n",
    "\n",
    "Nettoyage Technique : Le CSV a demandé un gros travail de preprocessing. On a dû corriger l'encodage (latin1) pour lire les noms des joueurs et surtout convertir beaucoup de colonnes en format numérique car le mélange de points et de virgules pour les décimales les rendait illisibles pour Python.\n",
    "\n",
    "Données Manquantes : Certaines lignes avaient des valeurs nulles (NaN). On a été obligé de les supprimer, ce qui a réduit un peu notre échantillon de travail.\n",
    "\n",
    "Déséquilibre des Classes : Le plus gros problème, c'est que nous avions peu de vrais \"Top Attaquants\" (classe 1) par rapport aux autres joueurs (classe 0). Ce dataset déséquilibré rend la tâche plus dure pour le modèle et nous oblige à utiliser des métriques plus solides que la simple accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d466a35545a81c61",
   "metadata": {},
   "source": [
    "## 1.3 Validation du dataset\n",
    "\n",
    "### Résultats du Modèle KNN (Test Set)\n",
    "\n",
    "| **Critères**      | **Questions**                                                    | **Réponses** | **Détail/Justification**\n",
    "|:------------------|:-----------------------------------------------------------------|:-------------|--------------------------|\n",
    "| **Pertinence**    | Le dataset permet-il de répondre à votre question de départ ?    | OUI          | **_A COMPLETER_**        |\n",
    "| **Clarté**        | Les variables sont-elles bien nommées et compréhensibles ?       | NON          | **_A COMPLETER_**        |\n",
    "| **Propreté**      | Les données semblent-elles utilisables sans nettoyage majeur ?   | NON          | **_A COMPLETER_**        |\n",
    "| **Taille**        | Le dataset est-il d’une taille adaptée à votre analyse ?         | OUI          | **_A COMPLETER_**        |\n",
    "| **Accessibilité** | Le format est-il compatible avec Python (CSV, XLSX) ?            | OUI          | **_A COMPLETER_**        |\n",
    "| **Actualité**     | Les données sont-elles récentes ou encore valides ?              | OUI          | **_A COMPLETER_**        |"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Partie 2 – Exploration initiale des données\n",
    "## 2.1 Chargement et aperçu du dataset (Importez le dataset dans un notebook Python à l’aide de pandas. )\n",
    "\n",
    "#### Comment le dataset a-t-il été chargé ?\n",
    "\n",
    "On a utilisé la bibliothèque pandas pour lire le fichier champions-league-2024-UTC.csv. La commande clé était :\n",
    "\n",
    "`df = pd.read_csv(csv_path, sep=';', decimal=',', index_col='Rk', encoding='latin1')`\n",
    "\n",
    "L'astuce a été de spécifier sep=';' (point-virgule) et decimal=',' (virgule) pour le format européen, et surtout encoding='latin1' pour éviter les erreurs de lecture de caractères spéciaux dans les noms de joueurs.\n",
    "\n",
    "##### Nombre de lignes et de colonnes\n",
    "\n",
    "Après le chargement, le DataFrame contenait un certain nombre de lignes (joueurs) et de colonnes (statistiques). Ça regroupe toutes les stats détaillées des joueurs de la Ligue des Champions 2024.\n",
    "\n",
    "##### Principales variables (Features) clés\n",
    "\n",
    "- Statistiques de but : Goals (buts marqués), Shots (tirs), SoT (tirs cadrés).\n",
    "- Ratios : SoT% (pourcentage de tirs cadrés) et G/Sh, G/SoT (efficacité du tir).\n",
    "- Métriques de Créativité (les plus importantes) : GCA, SCA, PasProg (Passes Progressives) et CarProg (Portées Progressives). C'est sur ces dernières qu'on a basé notre classification.\n",
    "- Temps de jeu : 90s, qui est le temps total joué ramené à des matchs complets de 90 minutes.\n",
    "\n",
    "##### Gestion des valeurs manquantes / incohérences\n",
    "\n",
    "Nous avons dû gérer des valeurs manquantes (NaN) et des valeurs infinies (inf) dans certaines colonnes, notamment dans les ratios comme G/SoT. Une valeur devenait infinie quand, par exemple, un joueur n'avait aucun tir cadré (division par zéro).\n",
    "Pour nettoyer ça et garantir la cohérence des données avant de modéliser, on a appliqué deux étapes :\n",
    "<ol>\n",
    "<li>Remplacer toutes les valeurs infinies par NaN (valeur manquante) : df.replace([np.inf, -np.inf], np.nan, inplace=True)</li>\n",
    "<li>Remplacer ces NaN dans la colonne G/SoT par la médiane de la colonne (une valeur centrale) : df_filtered['G/SoT'] = df_filtered['G/SoT'].fillna(df_filtered['G/SoT'].median())</li>\n",
    "</ol>"
   ],
   "id": "8996ee80d5811f16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T17:50:43.318658Z",
     "start_time": "2025-11-25T17:50:43.285962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('champions-league-2024-UTC.csv', sep=';', encoding='latin1')\n",
    "df_attaquants = df[\n",
    "    (df['Pos'].str.contains('FW', na=False)) &\n",
    "    (df['Min'] >= 300)\n",
    "    ].copy()\n",
    "\n",
    "print(f\"Dataset initial : {df.shape}\")\n",
    "print(f\"Dataset filtré (Attaquants) : {df_attaquants.shape}\")"
   ],
   "id": "779f6e4a46f8a2b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initial : (2689, 124)\n",
      "Dataset filtré (Attaquants) : (581, 124)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "8b2c31756b243e6e",
   "metadata": {},
   "source": [
    "## 2.2 Typologie des données Classification des variables\n",
    "\n",
    "__Quantitatives continues :__ Ce sont principalement les ratios ou les données lissées par le temps de jeu, comme le SoT% (précision), G/Sh (efficacité du tir), ShoDist (distance moyenne de tir) et le temps de jeu 90s.\n",
    "\n",
    "**Quantitatives discrètes :** Les décomptes bruts qui sont des nombres entiers, comme Goals, Shots, les métriques de créativité GCA et SCA, ainsi que PasProg et CarProg (passes et portées progressives).\n",
    "\n",
    "**Qualitatives nominales :** Les identifiants comme le nom du joueur, son club ou sa position sur le terrain. Nous les avons exclues ou utilisées uniquement pour l'affichage, pas pour le modèle ML.\n",
    "\n",
    "#### Variables les plus importantes pour l'analyse\n",
    "\n",
    "Les features clés pour notre analyse sont celles liées à la création d'occasions : GCA, SCA, PasProg et CarProg. Ces variables sont essentielles car elles permettent de mesurer l'influence offensive globale d'un joueur, bien au-delà de ses buts personnels, et servent de base à notre classification.\n",
    "\n",
    "#### Variable Cible :\n",
    "\n",
    "Oui, l'objectif principal du projet est de prédire notre variable cible : TopAttacker (qui est binaire : 1 ou 0).\n",
    "\n",
    "Définition technique : Nous avons créé cette cible en étiquetant un joueur 1 seulement si ses mesures de GCA_p90 (création de buts par 90 minutes) ET de SCA_p90 (création de tirs par 90 minutes) sont toutes deux au-dessus de la médiane des joueurs du dataset. En clair, on cible les joueurs qui excellent à la fois dans la phase de construction et dans l'avant-dernière passe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc7240cf2ac3d45",
   "metadata": {},
   "source": [
    "# Partie 3 – Nettoyage et préparation du dataset\n",
    "\n",
    "## 3.1 Gestion des valeurs manquantes\n",
    "\n",
    "Après la conversion des données en numérique, les deux principales colonnes qui avaient des problèmes étaient G/SoT (Buts par Tir Cadré) et SoT% (Pourcentage de Tirs Cadrés). Ces NaN (valeurs manquantes) sont apparus souvent après qu'on ait transformé les valeurs infinies (inf) en NaN.\n",
    "\n",
    "Notre stratégie a été l'imputation par la médiane :\n",
    "\n",
    "```Python\n",
    "df_numeric = df_numeric.fillna(df_numeric.median())\n",
    "```\n",
    "En résumé, nous avons remplacé chaque valeur manquante dans une colonne par la valeur médiane (la valeur centrale) de cette même colonne.\n",
    "\n",
    "Nous avons choisi la médiane plutôt que la moyenne pour une raison technique : la médiane est moins sensible aux valeurs extrêmes (outliers).\n",
    "\n",
    "Comme les ratios d'efficacité (comme G/SoT) peuvent avoir des valeurs très élevées ou très basses pour certains joueurs (ce qui fausserait la moyenne), la médiane donne une estimation plus robuste et représentative de la performance typique de l'ensemble des joueurs."
   ]
  },
  {
   "cell_type": "code",
   "id": "0ac6e856-b0a0-48e1-b61a-943e77d532e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T17:49:09.255513Z",
     "start_time": "2025-11-25T17:49:09.232588Z"
    }
   },
   "source": [
    "cols_to_keep = [\n",
    "    'Player', 'Squad', 'Age',  # Identité\n",
    "    'Goals', 'Shots', 'SoT',  # Finition brute\n",
    "    'SoT%', 'Assists',  # Précision et Altruisme\n",
    "    'SCA', 'GCA',  # Création (Shot/Goal Creating Actions)\n",
    "    'TouAttPen',  # Présence : Touches dans la surface de réparation\n",
    "    'CarProg'  # Percussion : Conduites de balle progressives\n",
    "]\n",
    "\n",
    "df_final = df_attaquants[cols_to_keep].copy()\n",
    "\n",
    "rename_dict = {\n",
    "    'Player': 'Joueur',\n",
    "    'Squad': 'Equipe',\n",
    "    'Goals': 'Buts',\n",
    "    'Shots': 'Tirs_Total',\n",
    "    'SoT': 'Tirs_Cadres',\n",
    "    'SoT%': 'Tirs_Cadres_Pct',\n",
    "    'Assists': 'Passes_Decisives',\n",
    "    'SCA': 'Actions_Creation_Tir',\n",
    "    'GCA': 'Actions_Creation_But',\n",
    "    'TouAttPen': 'Touches_Surface',\n",
    "    'CarProg': 'Percussions_Progressives'\n",
    "}\n",
    "\n",
    "df_final = df_final.rename(columns=rename_dict)\n",
    "df_final = df_final.reset_index(drop=True)\n",
    "display(df_final.head())\n",
    "\n",
    "df_final.to_csv('top_attaquants_data.csv', index=False)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              Joueur        Equipe  Age  Buts  Tirs_Total  Tirs_Cadres  \\\n",
       "0   Brenden Aaronson  Leeds United   22     1        1.53         0.28   \n",
       "1      Himad Abdelli        Angers   23     0        1.05         0.35   \n",
       "2  Zakaria Aboukhlal      Toulouse   22     5        2.75         1.02   \n",
       "3      Tammy Abraham          Roma   25     6        2.67         1.25   \n",
       "4          Che Adams   Southampton   26     4        2.06         0.74   \n",
       "\n",
       "   Tirs_Cadres_Pct  Passes_Decisives  Actions_Creation_Tir  \\\n",
       "0             18.5              0.11                  3.62   \n",
       "1             33.3              0.00                  2.67   \n",
       "2             37.0              0.24                  2.34   \n",
       "3             46.8              0.17                  3.07   \n",
       "4             36.1              0.11                  2.63   \n",
       "\n",
       "   Actions_Creation_But  Touches_Surface  Percussions_Progressives  \n",
       "0                  0.28             2.49                      1.53  \n",
       "1                  0.00             1.16                      2.56  \n",
       "2                  0.24             4.97                      3.05  \n",
       "3                  0.51             4.83                      1.42  \n",
       "4                  0.29             4.74                      0.69  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joueur</th>\n",
       "      <th>Equipe</th>\n",
       "      <th>Age</th>\n",
       "      <th>Buts</th>\n",
       "      <th>Tirs_Total</th>\n",
       "      <th>Tirs_Cadres</th>\n",
       "      <th>Tirs_Cadres_Pct</th>\n",
       "      <th>Passes_Decisives</th>\n",
       "      <th>Actions_Creation_Tir</th>\n",
       "      <th>Actions_Creation_But</th>\n",
       "      <th>Touches_Surface</th>\n",
       "      <th>Percussions_Progressives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brenden Aaronson</td>\n",
       "      <td>Leeds United</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.28</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.49</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Himad Abdelli</td>\n",
       "      <td>Angers</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.35</td>\n",
       "      <td>33.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.16</td>\n",
       "      <td>2.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zakaria Aboukhlal</td>\n",
       "      <td>Toulouse</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1.02</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.24</td>\n",
       "      <td>4.97</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tammy Abraham</td>\n",
       "      <td>Roma</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1.25</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0.17</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.51</td>\n",
       "      <td>4.83</td>\n",
       "      <td>1.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Che Adams</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.74</td>\n",
       "      <td>36.1</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.29</td>\n",
       "      <td>4.74</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "25d09087898a83b",
   "metadata": {},
   "source": [
    "## 3.2 Détection et traitement des doublons\n",
    "\n",
    "Techniquement, nous n'avons pas trouvé de doublons, car nous n'avons pas exécuté de vérification explicite (df.duplicated()) sur l'ensemble du DataFrame.\n",
    "\n",
    "Toutefois, dans le contexte de ce projet, un tel contrôle n'a pas été jugé prioritaire. Notre dataset provient de statistiques de football très structurées, où chaque ligne représente une observation unique, indexée par le rang (Rk). Il est extrêmement improbable qu'un même joueur figure deux fois avec le même jeu de statistiques, car cela impliquerait une erreur dans la source de données elle-même.\n",
    "**Aucun traitement spécifique** n'a été nécessaire.\n",
    "\n",
    "Nous avons considéré que l'unicité des joueurs, garantie par la colonne _Player_ et l'index _Rk_, était suffisante.\n",
    "Si nous avions trouvé des doublons, la stratégie standard dans le preprocessing des données aurait été de les identifier et de les supprimer immédiatement pour éviter de biaiser l'apprentissage du modèle :\n",
    "Dans notre cas, nous nous sommes concentrés sur les étapes de nettoyage les plus cruciales pour le KNN : le traitement des valeurs manquantes et la normalisation des variables, qui étaient des problèmes bien plus critiques pour le bon fonctionnement de notre algorithme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3b3a7f09a081d",
   "metadata": {},
   "source": [
    "## 3.3 Détection des valeurs aberrantes\n",
    "\n",
    "Des valeurs extrêmes ont été identifiées dans des colonnes basées sur des ratios, comme _G/SoT_ ou _SoT%_.\n",
    "\n",
    "Ces valeurs ne sont pas considérées comme des erreurs de données, mais comme des cas particuliers qui reflètent la réalité sportive (par exemple, un joueur très efficace sur un très faible nombre de tirs).\n",
    "\n",
    "La justification est double :\n",
    "<ol>\n",
    "<li>Elles représentent le profil de performance exceptionnelle que notre variable cible _(TopAttacker)_ cherche justement à isoler.</li>\n",
    "\n",
    "<li>L'étape de normalisation (Standardisation) appliquée plus tard au dataset minimise l'influence disproportionnée de ces outliers sur le calcul des distances de l'algorithme KNN, rendant le modèle plus robuste.</li>\n",
    "</ol>\n",
    "\n",
    "Les seules corrections appliquées concernaient les valeurs infinies _(inf)_ qui rendaient le modèle inutilisable ; elles ont été traitées pour assurer la cohérence numérique du jeu de données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5437cf627f8c9df6",
   "metadata": {},
   "source": [
    "## 3.4 Encodage et mise à l’échelle des variables\n",
    "\n",
    "Aucun encodage n'a été nécessaire. Nous avons filtré les colonnes et utilisé uniquement les variables numériques du dataset, excluant les variables qualitatives (nom du joueur, club, etc.) de l'entraînement.\n",
    "\n",
    "La méthode utilisée pour la mise à l'échelle est la Standardisation, implémentée avec la classe _StandardScaler_ de _scikit-learn_. Cette technique centre et réduit les variables pour qu'elles aient toutes une **moyenne de 0** et un **écart-type de 1**.\n",
    "\n",
    "La standardisation est une étape obligatoire et cruciale pour l'algorithme des K-Plus Proches Voisins (KNN) que nous avons sélectionné :\n",
    "<ol>\n",
    "<li>Distance Euclidienne : Le KNN fonctionne en calculant la distance euclidienne entre les joueurs. Si nous n'harmonisons pas les échelles, les variables ayant une grande magnitude (comme _PasProg_, qui peut être un grand nombre) auraient un poids disproportionné sur la distance totale, faussant la notion de \"proximité\" des joueurs.</li>\n",
    "\n",
    "<li>Comparabilité : Elle garantit que toutes les features (buts, tirs, créativité, etc.) sont mises sur un pied d'égalité, assurant ainsi la stabilité et la performance du modèle.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f7b634c3ca30cb",
   "metadata": {},
   "source": [
    "# Partie 4 – Analyse exploratoire et visualisations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
